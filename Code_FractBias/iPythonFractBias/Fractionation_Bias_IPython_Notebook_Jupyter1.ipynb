{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "\n",
    "\n",
    "#For importing data and parsing data\n",
    "from operator import itemgetter\n",
    "import pprint\n",
    "\n",
    "\n",
    "#Converting parsed data into raw parsed data output to csv\n",
    "import csv\n",
    "from itertools import islice, izip\n",
    "\n",
    "\n",
    "#For analyzing raw parsed data\n",
    "import collections, re\n",
    "\n",
    "    #had to uninstall python-dateutil and use old version dateutil 2.2 to avoid error\n",
    "    #sudo pip uninstall python-dateutil\n",
    "    #sudo pip install python-dateutil==2.2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "#had to install this using pip on local computer\n",
    "from natsort import natsorted, natsort_key\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Methods and Global Variables\"\"\"\n",
    "\n",
    "\n",
    "#For importing data and parsing\n",
    "synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/GecoFractBias/16888_25462.CDS-CDS.last.tdd10.cs0.filtered.dag.all.go_D20_g10_A5.aligncoords.Dm120.ma1.qac2.1.10.gcoords.txt'\n",
    "gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/GecoFractBias/Ananas_comosus_pineapple_annos1-cds0-id_typename-nu1-upa1-add_chr0.gid25462.gff'\n",
    "d = {}  # initialize dictionary to contain the array of syntenic genome1_chrs, genome1_genes, genome2_chrs, and genome2_genes\n",
    "genus_species = ''\n",
    "with open(gff_import_file) as gff_file:\n",
    "    for line in gff_file:\n",
    "        if line[0:15] == '##Organism name':\n",
    "            genus_species = line[17:-1]\n",
    "            species_name = genus_species.replace(' ','_')\n",
    "            species_name_filter = species_name.translate(None, '(){}[]')\n",
    "\n",
    "#Parsed data and raw output to csv\n",
    "gff_sort_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Pina-Rice/geco_output/ALL_GFF_sorted_\"+str(species_name_filter)+ \".txt\")\n",
    "synmap_dictionary_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Pina-Rice/geco_output/ALL_dictionary_syntenic genes_\" +str(species_name_filter)+ \".txt\")\n",
    "gff_genes = {}  # initializes dictionary for organization of genes on chromosomes within genome1 according to start bp\n",
    "fract_bias_raw_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Pina-Rice/geco_output/ALL_fractbias_\" +str(species_name_filter)+ \"output.csv\")\n",
    "\n",
    "#Analysis of parsed data\n",
    "retention_calc_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Pina-Rice/geco_output/Window_output_\"+str(species_name_filter+\".csv\"))\n",
    "target_lst = []\n",
    "query_lst = []\n",
    "\n",
    "def chr_id(input_dict):\n",
    "    for item in input_dict:\n",
    "        if not item in target_lst:\n",
    "            target_lst.append(item)\n",
    "        for gene in input_dict[item]:\n",
    "            for chr in input_dict[item][gene]:\n",
    "                if not chr in query_lst:\n",
    "                    query_lst.append(chr)\n",
    "\n",
    "#http://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator-in-python\n",
    "def window(seq, n):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "        \n",
    "#DATAPaths\n",
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasInput/Pina-rice/SynMapKsMerge120Sdepth10_Osativa-Acomosus2-1Acomv6.txt'\n",
    "\n",
    "#gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasInput/Sorghum-MaizeSynMap/Sorghum_bicolor_annos1-cds0-id_typename-nu1-upa1-add_chr0.gid6807.gff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Importing\n",
    "Reads SynMap and GFF CDS files and parse data into columns in array\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(synmap_import_file, 'r') as f:  # open SynMap file containing syntenic genes\n",
    "    cols = []  # list for parsing columns from SynMap data\n",
    "    for line in f:  # for loop to parse columns\n",
    "        new_line = line.replace('||', '\\t')  #converts || into tabs for universal delimination\n",
    "        if line[0] != '#' and line[0] != '\\n':  #sorts out columns containing syntenic block information/headings\n",
    "            cols = new_line.split('\\t', )  #splits all syntenic gene pair lines into parsed columns in a list\n",
    "            global target_chr\n",
    "            global target_gene\n",
    "            global query_chr\n",
    "            global query_gene\n",
    "            target_chr = cols[15]\n",
    "            target_gene = str(cols[18])  #puts all genome1_genes with synteny into a list\n",
    "            query_chr = str(cols[3])  #puts all genome2_chrs with synteny to genes in genome1 into a list\n",
    "            query_gene = str(cols[6])  #puts all genome2_genes with synteny to genes in a genome1 into a list\n",
    "\n",
    "            if not target_chr in d:\n",
    "                d[target_chr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "            if not target_gene in d[target_chr]:\n",
    "                d[target_chr][target_gene] = {}  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "            if not query_chr in d[target_chr][target_gene]:\n",
    "                d[target_chr][target_gene][query_chr] = query_gene  #initializes nested dictionary-third level at genome2_chr\n",
    "            \n",
    "            #print cols[15]            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Reads GFF from genome1 (target) and parses data'''\n",
    "with open(gff_import_file, 'r') as g:  # opens gff file\n",
    "    gffcols = []  #list of parsed gff columns\n",
    "    chr = []  #initialize list of chromosomes present in genome1 gff file\n",
    "    for line in g:\n",
    "        new_line = line.replace(';', '\\t')  #makes subdelims universal in gff file from CoGe\n",
    "        new_line = new_line.replace('Name=', '')  #strips Name= off gene_name in gff file from CoGe\n",
    "        #new_line = new_line.replace('LG', '')\n",
    "\n",
    "        if new_line[0] != '#' and new_line[0] != '\\n':  #selects only lines with CDS information\n",
    "            gffcols = new_line.split('\\t', )  #parses all columns\n",
    "            if gffcols[2] == 'mRNA' and 'scaffold' not in gffcols[0]:  #selects only 'mRNA' lines for consideration\n",
    "                chr = gffcols[0]  #adds genome1_chrs to list\n",
    "                gene_name = gffcols[10]  #adds genome1_genes to list\n",
    "                start = int(gffcols[3])  #adds genome1_gene start bp to list for ordering as integer\n",
    "                stop = int(gffcols[4])  #adds genome1_gene stop bp to list ?for ordering? as integer\n",
    "                if not chr in gff_genes:\n",
    "                    gff_genes[chr] = []  #initializes chr list in dictionary if chr does not exist yet\n",
    "                gff_genes[chr].append(dict(gene_name=gene_name, start=start, stop=stop))\n",
    "\n",
    "'''Sorts GFF genes within chromosome by start position'''\n",
    "for chr in gff_genes:\n",
    "    gff_genes_sorted = sorted(gff_genes[chr], key=itemgetter('start'))  #Creates dictionary for searching genes against::CONSIDER sorting on midpoint of genes rather than\n",
    "    gff_genes[chr] = gff_genes_sorted\n",
    "\n",
    "    #CONSIDER WRITING A CHECK PROGRAM TO RETURN TRUE IF ALL VALUES ARE SORTED OR FALSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Writes out SynMap dictionary and sorted GFF gene list to document for parsed output'''\n",
    "\n",
    "with open(str(gff_sort_output_file), 'w') as h:\n",
    "\th.write(str(gff_genes))\n",
    "with open(synmap_dictionary_output_file, 'w+') as i:\n",
    "    i.write(str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Determine syntenic gene pairs present and output Raw Data CSV file from parsed data'''\n",
    "\n",
    "\n",
    "chr_id(d)\n",
    "target_lst = natsorted(target_lst)\n",
    "query_lst = natsorted(query_lst)\n",
    "windanalysis_input_dict = {}\n",
    "\n",
    "with open(str(fract_bias_raw_output_file), 'w') as csvfile:\n",
    "    headers = ['Target Chromosome', 'Target Gene Name', 'Gene Order on Target Chromosome']\n",
    "    headers.extend(query_lst)\n",
    "    headers.extend(query_lst)\n",
    "    writer = csv.writer(csvfile, dialect='excel', delimiter=',', lineterminator='\\n')\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    for tchr in gff_genes:\n",
    "        col0 = chr #writes Pineapple chr number\n",
    "        count = 0\n",
    "        for diction in gff_genes[tchr]:\n",
    "            gene = diction['gene_name']\n",
    "            col1 = gene #writes pineapple gene name\n",
    "            count += 1\n",
    "            col2 = count #writes pineapple gene number on pineapple chr\n",
    "            #Find the query chr genes and output to columns: first gff info (col0-3), query chr (col 4-n), query chr-gene (col n+1-m)\n",
    "            syntenic_query_gene_presence_data = []\n",
    "            syntenic_query_gene_name = []\n",
    "            for qchr in query_lst:\n",
    "                if not tchr in windanalysis_input_dict:\n",
    "                    windanalysis_input_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "                if not qchr in windanalysis_input_dict[tchr]:\n",
    "                    windanalysis_input_dict[tchr][qchr] = []  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "                try:\n",
    "                    syn_gene = d[tchr][gene][qchr]\n",
    "                    syntenic_query_gene_presence_data.append(True)\n",
    "                    syntenic_query_gene_name.append(syn_gene)\n",
    "                    windanalysis_input_dict[tchr][qchr].append(True)\n",
    "                except KeyError:\n",
    "                    syntenic_query_gene_presence_data.append(False)\n",
    "                    syntenic_query_gene_name.append(\".\")\n",
    "                    windanalysis_input_dict[tchr][qchr].append(False)\n",
    "            rows = [tchr, col1, col2]\n",
    "            rows.extend(syntenic_query_gene_presence_data)\n",
    "            rows.extend(syntenic_query_gene_name)\n",
    "            writer.writerow(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# '''Analysis: for each chromosome in genome1 read the genes on a chromosome and compare to subgenome array of syntenic genes'''\n",
    "\n",
    "data_output0 = []\n",
    "data_output1 = []\n",
    "data_output2 = []\n",
    "data_output3 = []\n",
    "output_dict = {}\n",
    "#Process windows 100genes/sliding window and \n",
    "#output to nested dictionary data structure output_dict{target chr:}{query chr}{window count:retention%}\n",
    "for tchr in windanalysis_input_dict:\n",
    "    tchr_counter = tchr\n",
    "    for qchr in windanalysis_input_dict[tchr]:\n",
    "        counter = 0\n",
    "        qchr_counter = qchr\n",
    "        if not tchr in output_dict:\n",
    "            output_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "        if not qchr in output_dict[tchr]:\n",
    "            output_dict[tchr][qchr] = {}  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "\n",
    "        try:\n",
    "            if (int(len(windanalysis_input_dict[tchr][qchr]))) >= 100:\n",
    "                for each in window(windanalysis_input_dict[tchr][qchr], 100):\n",
    "                    counter += 1\n",
    "                    data_output2 = sum(each)\n",
    "                    output_dict[tchr][qchr][counter] = data_output2                       \n",
    "        except KeyError:\n",
    "            continue\n",
    "                            \n",
    "#Sort output_dict for tchr alphanumberic at top level \n",
    "alphanumbsort = lambda k,v: [k, int(v)]\n",
    "output_dict = collections.OrderedDict(sorted(output_dict.items(), key=lambda t: alphanumbsort(*re.match(r'([a-zA-Z]+)(\\d+)',t[0]).groups())))\n",
    "\n",
    "\"\"\"#Output processed data to a csv file for downstream analysis\n",
    "with open(retention_calc_output_file, 'wb') as csvf:\n",
    "    headers = ['Target Chromosome', 'Query Chromosome' 'Window Iteration (x-axis)']\n",
    "    headers.extend(query_lst)\n",
    "    writer = csv.writer(csvf, dialect='excel', delimiter=',', lineterminator='\\n')\n",
    "    writer.writerow(headers)\n",
    "    for tchr in windanalysis_input_dict:\n",
    "        for qchr in windanalysis_input_dict[tchr]:            \n",
    "            #Prints into two columns\n",
    "            writer.writerows(izip( output_dict[tchr][qchr]))\"\"\"\n",
    "\n",
    "\n",
    "##Statistics Output NEEDS FIXING\n",
    "\n",
    "#for tchr in output_dict:\n",
    "    #for qchr in output_dict[tchr]:\n",
    "        #print np.mean(output_dict[tchr][qchr])\n",
    "        #print np.median_grouped(output_dict[tchr][qchr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#define figure size, column layout, grid layout\n",
    "figsize = (18 , 60)\n",
    "cols = 2\n",
    "gs = gridspec.GridSpec(len(output_dict) // cols + 1, cols)\n",
    "\n",
    "# These are the \"Tableau 20\" colors as RGB  \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)] \n",
    "\n",
    "tableau10blind = [(0, 107, 164), (255, 128, 14), (171, 171, 171), (89, 89, 89),\n",
    "             (95, 158, 209), (200, 82, 0), (137, 137, 137), (163, 200, 236),\n",
    "             (255, 188, 121), (207, 207, 207)]\n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts  \n",
    "for i in range(len(tableau20)):  \n",
    "    r, g, b = tableau20[i]  \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
    "    tableau10blind[i]=(r / 255., g / 255., b / 255.)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "subplt_count = -1\n",
    "ax = []\n",
    "for tchr in output_dict:\n",
    "    subplt_count += 1\n",
    "    print \"Plotting target chromosome: \"+str(subplt_count)\n",
    "    count = 0 \n",
    "    row = (subplt_count // cols)\n",
    "    col = subplt_count % cols\n",
    "    ax.append(fig.add_subplot(gs[row, col]))\n",
    "    \n",
    "    for qchr in output_dict[tchr]:\n",
    "        count += 1\n",
    "        if (max(output_dict[tchr][qchr].itervalues()))>0:\n",
    "            x = output_dict[tchr][qchr].keys()\n",
    "            y = output_dict[tchr][qchr].values()    \n",
    "        else:\n",
    "            continue\n",
    "        ax[-1].spines[\"top\"].set_visible(False)\n",
    "        ax[-1].spines[\"right\"].set_visible(False)\n",
    "        ax[-1].get_xaxis().tick_bottom()\n",
    "        ax[-1].get_yaxis().tick_left()\n",
    "        ax[-1].plot(x, y, color=tableau20[count], lw=3)\n",
    "        ax[-1].set_title(label='Target Chromosome: '+species_name_filter+\" \"+ tchr, fontweight='bold', fontsize=14)\n",
    "        ax[-1].set_xlabel('Window Iteration', fontsize=12, fontweight='bold')\n",
    "        ax[-1].set_ylabel('% Retention', fontsize=12, fontweight='bold')\n",
    "        if (max(output_dict[tchr][qchr].itervalues()))>0:\n",
    "            ax[-1].legend(output_dict[tchr], loc=1, frameon=False, title=\"Query Chromosome\", fontsize=10)\n",
    "        import operator\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Export Processed Fractional Bias Data to JSON File\n",
    "import json\n",
    "import csv\n",
    "\n",
    "with open(\"myFile.json\", \"w\") as f:\n",
    "    json.dump(output_dict,f)\n",
    "    \n",
    "x = json.loads(output_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = csv.writer(open(\"test.csv\", \"wb+\"))\n",
    "\n",
    "# Write CSV Header, If you dont need that, remove this line\n",
    "#f.writerow([\"pk\", \"model\", \"codename\", \"name\", \"content_type\"])\n",
    "\n",
    "for x in x:\n",
    "    f.writerow([x[\"tchr\"], \n",
    "                x[\"tchr\"][\"qchr\"]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''import os\n",
    "from lightning import Lightning\n",
    "\n",
    "from numpy import random, asarray, arange\n",
    "from sklearn import datasets\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from seaborn import color_palette\n",
    "\n",
    "\n",
    "# replace with your own host and credentials, e.g. http://localhost:3000 or http://my-lightning-server.herokuapp.com\n",
    "host = 'http://lightning-docs.herokuapp.com'\n",
    "auth = (os.getenv('LIGHTNING_USERNAME'), os.getenv('LIGHTNING_PASSWORD'))\n",
    "\n",
    "lgn = Lightning(ipython=True, host=host, auth=auth)\n",
    "lgn.create_session('fractbias');'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
