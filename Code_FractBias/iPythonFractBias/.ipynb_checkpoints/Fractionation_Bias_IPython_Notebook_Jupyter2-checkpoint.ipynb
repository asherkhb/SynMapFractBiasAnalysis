{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For importing data and parsing data\n",
    "from operator import itemgetter\n",
    "import pprint\n",
    "\n",
    "\n",
    "#Converting parsed data into raw parsed data output to csv\n",
    "import csv\n",
    "from itertools import islice, izip\n",
    "\n",
    "\n",
    "#For analyzing raw parsed data\n",
    "import collections, re\n",
    "from collections import OrderedDict\n",
    "\n",
    "    #had to uninstall python-dateutil and use old version dateutil 2.2 to avoid error\n",
    "    #sudo pip uninstall python-dateutil\n",
    "    #sudo pip install python-dateutil==2.2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "#had to install this using pip on local computer\n",
    "from natsort import natsorted, natsort_key\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For importing data and parsing\n",
    "synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/Sorghum_maize_synmap_results.txt'\n",
    "gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/Sorghum_bicolor_6807_prodrun.gff'\n",
    "d = {}  # initialize dictionary to contain the array of syntenic genome1_chrs, genome1_genes, genome2_chrs, and genome2_genes\n",
    "genus_species = ''\n",
    "with open(gff_import_file) as gff_file:\n",
    "    for line in gff_file:\n",
    "        if line[0:15] == '##Organism name':\n",
    "            genus_species = line[17:-1]\n",
    "            species_name = genus_species.replace(' ','_')\n",
    "            species_name_filter = species_name.translate(None, '(){}[]')\n",
    "\n",
    "args_target = '6807' #sorghum \n",
    "#\"19867\" #arabidopsis\n",
    "#'6807' #sorghum \n",
    "\n",
    "            \n",
    "#Parsed data and raw output to csv\n",
    "gff_sort_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Sorghum-Maize/ALL_GFF_sorted_\"+str(species_name_filter)+ \".txt\")\n",
    "synmap_dictionary_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Sorghum-Maize/ALL_dictionary_syntenic genes_\" +str(species_name_filter)+ \".txt\")\n",
    "gff_genes = {}  # initializes dictionary for organization of genes on chromosomes within genome1 according to start bp\n",
    "fract_bias_raw_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Sorghum-Maize/ALL_fractbias_\" +str(species_name_filter)+ \"output.csv\")\n",
    "\n",
    "#Analysis of parsed data\n",
    "retention_calc_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Sorghum-Maize/Window_output_\"+str(species_name_filter+\".csv\"))\n",
    "target_lst = []\n",
    "query_lst = []\n",
    "\n",
    "def chr_id(input_dict):\n",
    "    for item in input_dict:\n",
    "        if not item in target_lst:\n",
    "            target_lst.append(item)\n",
    "        for gene in input_dict[item]:\n",
    "            for chr in input_dict[item][gene]:\n",
    "                if not chr in query_lst:\n",
    "                    query_lst.append(chr)\n",
    "\n",
    "#http://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator-in-python\n",
    "def window(seq, n):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pina & Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasInput/Pina-rice/SynMapKsMerge120Sdepth10_Osativa-Acomosus2-1Acomv6.txt'\n",
    "\n",
    "#gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasInput/Pina-rice/Ananas_comosus_pineapple_v6.gff'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorghum & Maize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/Sorghum_maize_synmap_results.txt'\n",
    "#gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/Sorghum_bicolor_annos1-cds0-id_typename-nu1-upa1-add_chr0.gid6807.gff'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brassicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/BrassicaRapa-ArabidopsisKsSynMap.txt'\n",
    "#gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/Arabidopsis_thaliana_Col-0_thale_cress_annos1-cds0-id_typename-nu1-upa1-add_chr0.gid19867.gff'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data and Making Data Structures\n",
    "\n",
    "Reads SynMap and GFF files and parse data into data arrays. \n",
    "\n",
    "SynMap data is put into nested dictionary called 'd':\n",
    "d{target_chr\n",
    "    {target_gene\n",
    "        {query_chr\n",
    "            {query gene}\n",
    "  }}}\n",
    "\n",
    "GFF data is put into a nested dictionary call 'gff_genes':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads SynMap and GFF files and parse data into columns in array\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(synmap_import_file, 'r') as f:  # open SynMap file containing syntenic genes\n",
    "    synmap_rowcount = 0\n",
    "    cols = []  # list for parsing columns from SynMap data\n",
    "    for line in f:  # for loop to parse columns\n",
    "        new_line = line.replace('||', '\\t')  #converts || into tabs for universal delimination\n",
    "        if line[0] != '#' and line[0] != '\\n':  #sorts out columns containing syntenic block information/headings\n",
    "            cols = new_line.split('\\t', )  #splits all syntenic gene pair lines into parsed columns in a list\n",
    "            synmap_rowcount += 1\n",
    "            global target_chr\n",
    "            global target_gene\n",
    "            global query_chr\n",
    "            global query_gene\n",
    "            if synmap_rowcount == 1:            \n",
    "                #clean ID subgenome A from the column on left of data\n",
    "                ida = cols[2]\n",
    "                ida = ida[1:cols[2].index('_')]\n",
    "            if args_target == ida:\n",
    "                if 'scaffold' not in cols[3] and 'Scaffold' not in cols[3]:\n",
    "                    target_chr = cols[3]\n",
    "                    target_gene = str(cols[6]).rstrip('.')  #puts all genome1_genes with synteny into a list\n",
    "                if 'scaffold' not in cols[15] and 'Scaffold' not in cols[15]:\n",
    "                    query_chr = str(cols[15])  #puts all genome2_chrs with synteny to genes in genome1 into a list\n",
    "                    query_gene = str(cols[18]).rstrip('.')  #puts all genome2_genes with synteny to genes in a genome1 into a list\n",
    "            else:\n",
    "                if 'scaffold' not in cols[15] and 'Scaffold' not in cols[15]:\n",
    "                    target_chr = cols[15]\n",
    "                    target_gene = str(cols[18])  #puts all genome1_genes with synteny into a list\n",
    "                if 'scaffold' not in cols[3] and 'Scaffold' not in cols[3]:\n",
    "                    query_chr = str(cols[3])  #puts all genome2_chrs with synteny to genes in genome1 into a list\n",
    "                    query_gene = str(cols[6])  #puts all genome2_genes with synteny to genes in a genome1 into a list\n",
    "\n",
    "            if not target_chr in d:\n",
    "                d[target_chr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "            if not target_gene in d[target_chr]:\n",
    "                d[target_chr][target_gene] = {}  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "            if not query_chr in d[target_chr][target_gene]:\n",
    "                d[target_chr][target_gene][query_chr] = query_gene  #initializes nested dictionary-third level at genome2_chr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Reads GFF from target genome and puts into data strcuture gff_genes'''\n",
    "with open(gff_import_file, 'r') as g:  # opens gff file\n",
    "    gffcols = []  #list of parsed gff columns\n",
    "    chr = []  #initialize list of chromosomes present in genome1 gff file\n",
    "    for line in g:\n",
    "        new_line = line.replace(';', '\\t')  #makes subdelims universal in gff file from CoGe\n",
    "        new_line = new_line.replace('Name=', '')  #strips Name= off gene_name in gff file from CoGe\n",
    "\n",
    "        if new_line[0] != '#' and new_line[0] != '\\n':  #selects only lines with CDS information\n",
    "            gffcols = new_line.split('\\t', )  #parses all columns\n",
    "            if gffcols[2] == 'gene' and 'scaffold' not in gffcols[0]:  #selects only 'mRNA' lines for consideration\n",
    "                chr = gffcols[0]  #adds genome1_chrs to list\n",
    "                gene_name = gffcols[8]\n",
    "                gene_name1 = gene_name[3:] #adds genome1_genes to list\n",
    "                start = int(gffcols[3])  #adds genome1_gene start bp to list for ordering as integer\n",
    "                stop = int(gffcols[4])  #adds genome1_gene stop bp to list ?for ordering? as integer\n",
    "                if not chr in gff_genes:\n",
    "                    gff_genes[chr] = []  #initializes chr list in dictionary if chr does not exist yet\n",
    "                gff_genes[chr].append(dict(gene_name=gene_name1, start=start, stop=stop))\n",
    "                \n",
    "'''Sorts GFF genes within target chromosomes by start position'''\n",
    "for chr in gff_genes:\n",
    "    gff_genes_sorted = sorted(gff_genes[chr], key=itemgetter('start'))  #Creates dictionary for searching genes against::CONSIDER sorting on midpoint of genes rather than\n",
    "    gff_genes[chr] = gff_genes_sorted\n",
    "\n",
    "    #CONSIDER WRITING A CHECK PROGRAM TO RETURN TRUE IF ALL VALUES ARE SORTED OR FALSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Writes out SynMap dictionary and sorted GFF gene list to document for parsed output'''\n",
    "\n",
    "with open(str(gff_sort_output_file), 'w') as h:\n",
    "\th.write(str(gff_genes))\n",
    "with open(synmap_dictionary_output_file, 'w+') as i:\n",
    "    i.write(str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Determine syntenic gene pairs present and output Raw Data CSV file from parsed data'''\n",
    "\n",
    "\n",
    "chr_id(d)\n",
    "target_lst = natsorted(target_lst)\n",
    "query_lst = natsorted(query_lst)\n",
    "windanalysis_input_dict = {}\n",
    "\n",
    "with open(str(fract_bias_raw_output_file), 'w') as csvfile:\n",
    "    headers = ['Target Chromosome', 'Target Gene Name', 'Gene Order on Target Chromosome']\n",
    "    headers.extend(query_lst)\n",
    "    headers.extend(query_lst)\n",
    "    writer = csv.writer(csvfile, dialect='excel', delimiter=',', lineterminator='\\n')\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    for tchr in gff_genes:\n",
    "        col0 = chr #writes Pineapple chr number\n",
    "        count = 0\n",
    "        for diction in gff_genes[tchr]:\n",
    "            gene = diction['gene_name']\n",
    "            col1 = gene #writes pineapple gene name\n",
    "            count += 1\n",
    "            col2 = count #writes pineapple gene number on pineapple chr\n",
    "            #Find the query chr genes and output to columns: first gff info (col0-3), query chr (col 4-n), query chr-gene (col n+1-m)\n",
    "            syntenic_query_gene_presence_data = []\n",
    "            syntenic_query_gene_name = []\n",
    "            for qchr in query_lst:\n",
    "                if not tchr in windanalysis_input_dict:\n",
    "                    windanalysis_input_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "                if not qchr in windanalysis_input_dict[tchr]:\n",
    "                    windanalysis_input_dict[tchr][qchr] = []  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "                try:\n",
    "                    syn_gene = d[tchr][gene][qchr]\n",
    "                    syntenic_query_gene_presence_data.append(True)\n",
    "                    syntenic_query_gene_name.append(syn_gene)\n",
    "                    windanalysis_input_dict[tchr][qchr].append(True)\n",
    "                except KeyError:\n",
    "                    syntenic_query_gene_presence_data.append(False)\n",
    "                    syntenic_query_gene_name.append(\".\")\n",
    "                    windanalysis_input_dict[tchr][qchr].append(False)\n",
    "            rows = [tchr, col1, col2]\n",
    "            rows.extend(syntenic_query_gene_presence_data)\n",
    "            rows.extend(syntenic_query_gene_name)\n",
    "            writer.writerow(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Data Structures\n",
    "\n",
    "Looks through each chromosome in target genome (tchr), and goes through each gene gene on that target chromosome (determined by the GFF uploaded above according to bp position on that target chromosome) to compare to the query genome (query chromsomes). If a target gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# '''Analysis: for each chromosome in genome1 read the genes on a chromosome and compare to subgenome array of syntenic genes'''\n",
    "\n",
    "data_output0 = []\n",
    "data_output1 = []\n",
    "data_output2 = []\n",
    "data_output3 = []\n",
    "output_dict = {}\n",
    "alphanum_output_dict = {}\n",
    "numsorted_output_dict = {}\n",
    "window_size = 100\n",
    "#Process windows 100genes/sliding window and \n",
    "#output to nested dictionary data structure output_dict{target chr:}{query chr}{window count:retention%}\n",
    "for tchr in windanalysis_input_dict:\n",
    "    tchr_counter = tchr\n",
    "    for qchr in windanalysis_input_dict[tchr]:\n",
    "        counter = 0\n",
    "        qchr_counter = qchr\n",
    "        if not tchr in output_dict:\n",
    "            output_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "        if not qchr in output_dict[tchr]:\n",
    "            output_dict[tchr][qchr] = {}  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "        try:\n",
    "            if (int(len(windanalysis_input_dict[tchr][qchr]))) >= window_size:\n",
    "                for each in window(windanalysis_input_dict[tchr][qchr], window_size):\n",
    "                    counter += 1\n",
    "                    data_output2 = float(sum(each)) / float(window_size)\n",
    "                    output_dict[tchr][qchr][counter] = round(data_output2*100.) \n",
    "                    \n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "print \n",
    "#BRASSICA DATA DOES NOT PROCESS         \n",
    "            \n",
    "#Sort output_dict for tchr alphanumberic at top level\n",
    "#if tchr are only integers (not alpha&numeric) the except statement will sort just integers\n",
    "try:\n",
    "    alphanumbsort = lambda k,v: [k, int(v)]\n",
    "    alphanum_output_dict = output_dict = collections.OrderedDict(sorted(output_dict.items(), key=lambda t: alphanumbsort(*re.match(r'([a-zA-Z]+)(\\d+)',t[0]).groups())))\n",
    "    print \"alphanum\"\n",
    "except AttributeError:\n",
    "    for tchr in output_dict:\n",
    "        print tchr\n",
    "        for qchr in output_dict[tchr]:\n",
    "            print qchr\n",
    "            numsorted_output_dict = natsorted(output_dict[tchr][qchr])\n",
    "    print \"numsorted\"    \n",
    "\n",
    "if alphanum_output_dict == output_dict:\n",
    "    print \"alphanum == output_dict\"\n",
    "elif numsorted_output_dict == output_dict:\n",
    "    print \"numsorted output == output_dict\"\n",
    "else:\n",
    "    print \"none equal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Output processed data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(retention_calc_output_file, 'wb') as csvf:\n",
    "    headers = ['Target Chromosome', 'Query Chromosome' 'Window Iteration (x-axis)']\n",
    "    headers.extend(query_lst)\n",
    "    writer = csv.writer(csvf, dialect='excel', delimiter=',', lineterminator='\\n')\n",
    "    writer.writerow(headers)\n",
    "    for tchr in windanalysis_input_dict:\n",
    "        for qchr in windanalysis_input_dict[tchr]:            \n",
    "            #Prints into two columns\n",
    "            writer.writerows(izip( output_dict[tchr][qchr]))\n",
    "\n",
    "##Statistics Output NEEDS FIXING\n",
    "\n",
    "#for tchr in output_dict:\n",
    "    #for qchr in output_dict[tchr]:\n",
    "        #print np.mean(output_dict[tchr][qchr])\n",
    "        #print np.median_grouped(output_dict[tchr][qchr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#define figure size, column layout, grid layout\n",
    "figsize = (15, 20)\n",
    "cols = 2\n",
    "gs = gridspec.GridSpec(len(output_dict) // cols + 1, cols)\n",
    "\n",
    "# These are the \"Tableau 20\" colors as RGB  \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)] \n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts  \n",
    "for i in range(len(tableau20)):  \n",
    "    r, g, b = tableau20[i]  \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "subplt_count = -1\n",
    "ax = []\n",
    "for tchr in output_dict:\n",
    "    subplt_count += 1\n",
    "    print \"Plotting target chromosome: \"+str(subplt_count)\n",
    "    count = 0 \n",
    "    row = (subplt_count // cols)\n",
    "    col = subplt_count % cols\n",
    "    ax.append(fig.add_subplot(gs[row, col]))\n",
    "    \n",
    "    for qchr in output_dict[tchr]:\n",
    "        count += 1\n",
    "        if (max(output_dict[tchr][qchr].itervalues()))>0:\n",
    "            x = output_dict[tchr][qchr].keys()\n",
    "            y = output_dict[tchr][qchr].values()    \n",
    "        else:\n",
    "            continue\n",
    "        ax[-1].spines[\"top\"].set_visible(False)\n",
    "        ax[-1].spines[\"right\"].set_visible(False)\n",
    "        ax[-1].get_xaxis().tick_bottom()\n",
    "        ax[-1].get_yaxis().tick_left()\n",
    "        ax[-1].plot(x, y, color=tableau20[count], lw=2)\n",
    "        ax[-1].set_title(label='Target Chromosome: '+species_name_filter+\" \"+ tchr, fontweight='bold', fontsize=14)\n",
    "        ax[-1].set_xlabel('Window Iteration', fontsize=12, fontweight='bold')\n",
    "        ax[-1].set_ylabel('% Retention', fontsize=12, fontweight='bold')\n",
    "        if (max(output_dict[tchr][qchr].itervalues()))>0:\n",
    "            ax[-1].legend(output_dict[tchr], loc=1, frameon=False, title=\"Query Chromosome\", fontsize=10)\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Export Processed Fractional Bias Data to JSON File\n",
    "import json\n",
    "import csv\n",
    "\n",
    "with open(\"myFile.json\", \"w\") as f:\n",
    "    json.dump(output_dict,f)\n",
    "    \n",
    "x = json.loads(output_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = csv.writer(open(\"test.csv\", \"wb+\"))\n",
    "\n",
    "# Write CSV Header, If you dont need that, remove this line\n",
    "#f.writerow([\"pk\", \"model\", \"codename\", \"name\", \"content_type\"])\n",
    "\n",
    "for x in x:\n",
    "    f.writerow([x[\"tchr\"], \n",
    "                x[\"tchr\"][\"qchr\"]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''import os\n",
    "from lightning import Lightning\n",
    "\n",
    "from numpy import random, asarray, arange\n",
    "from sklearn import datasets\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from seaborn import color_palette\n",
    "\n",
    "\n",
    "# replace with your own host and credentials, e.g. http://localhost:3000 or http://my-lightning-server.herokuapp.com\n",
    "host = 'http://lightning-docs.herokuapp.com'\n",
    "auth = (os.getenv('LIGHTNING_USERNAME'), os.getenv('LIGHTNING_PASSWORD'))\n",
    "\n",
    "lgn = Lightning(ipython=True, host=host, auth=auth)\n",
    "lgn.create_session('fractbias');'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
